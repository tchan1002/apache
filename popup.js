// Sherpa 2 (Apache) - Voice-First Assistant
// Minimal voice interface with persistent listening

// State management
let recognition = null;
let isListening = false;
let isVoiceSupported = false;
let microphonePermissionGranted = false;
let currentState = 'idle'; // idle, listening, processing, ready, error

// DOM elements
const sherpaCircle = document.getElementById('sherpa-circle');
const sherpaIcon = document.getElementById('sherpa-icon');
const statusText = document.getElementById('status-text');

// Debug log elements
const debugEl = document.getElementById('debug');
const debugContentEl = document.getElementById('debug-content');
const debugHeaderEl = document.getElementById('debug-header');
const copyLogBtnEl = document.getElementById('copy-log-btn');
const clearLogBtnEl = document.getElementById('clear-log-btn');
const logToggleBtnEl = document.getElementById('log-toggle-btn');
const logToggleIconEl = document.querySelector('.log-toggle-icon');

// Log management
let logBuffer = [];
let logUpdateInterval = null;
const MAX_LOG_ENTRIES = 100;

// Voice recognition timeout
let voiceTimeout = null;
const VOICE_TIMEOUT_MS = 10000; // 10 seconds of silence

// Wake word detection
let wakeWordDetected = false;
const WAKE_WORDS = ['hey sherpa', 'hey sherpa 2', 'sherpa'];

// Initialize on load
document.addEventListener('DOMContentLoaded', async () => {
  addDebugLog('üå≤ Sherpa 2 (Apache) - Voice-First Assistant loaded');
  
  // Set up debug log event handlers
  setupDebugLogHandlers();
  
  // Initialize log as collapsed
  debugEl.classList.add('collapsed');
  document.body.classList.remove('log-expanded');
  logToggleIconEl.textContent = '+';
  
  // Initialize voice recognition
  await initializeVoiceRecognition();
  
  // Set up click handler
  sherpaCircle.addEventListener('click', handleSherpaClick);
  
  // Add spacebar support for voice input
  document.addEventListener('keydown', handleSpaceKey);
  
  // Update initial state
  updateState('idle');
});

// Initialize voice recognition
async function initializeVoiceRecognition() {
  addDebugLog('üé§ Initializing voice recognition...');
  
  // Check if browser supports speech recognition
  if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
    isVoiceSupported = true;
    addDebugLog('üé§ Voice recognition supported');
    
    try {
      // Initialize speech recognition
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognition = new SpeechRecognition();
      
      // Configure recognition settings
      recognition.continuous = false;
      recognition.interimResults = false;
      recognition.lang = 'en-US';
      
      // Set up event handlers
      recognition.onstart = handleVoiceStart;
      recognition.onresult = handleVoiceResult;
      recognition.onerror = handleVoiceError;
      recognition.onend = handleVoiceEnd;
      
      addDebugLog('üé§ Voice recognition initialized successfully');
      updateState('ready');
  } catch (error) {
      addDebugLog(`üçÇ Voice recognition initialization failed: ${error.message}`);
      isVoiceSupported = false;
      updateState('error');
    }
    } else {
    isVoiceSupported = false;
    addDebugLog('üçÇ Voice recognition not supported in this browser');
    updateState('error');
  }
}

// Handle Space key press for voice input
function handleSpaceKey(event) {
  if (event.code === 'Space') {
    // Prevent default space behavior (scrolling)
    event.preventDefault();
    
    if (currentState === 'idle' || currentState === 'ready') {
      addDebugLog('‚å®Ô∏è Space key pressed - starting voice input');
      startListening();
    } else if (currentState === 'listening') {
      addDebugLog('‚å®Ô∏è Space key pressed - stopping voice input');
      stopListening();
    } else if (currentState === 'error') {
      addDebugLog('‚å®Ô∏è Space key pressed - retrying voice recognition');
      initializeVoiceRecognition();
    }
  }
}

// Handle Sherpa circle click
async function handleSherpaClick() {
  addDebugLog('üñ±Ô∏è Sherpa circle clicked');
  
  if (currentState === 'idle' || currentState === 'ready') {
    addDebugLog('üé§ Starting voice input...');
    await startListening();
  } else if (currentState === 'listening') {
    addDebugLog('üé§ Stopping voice input...');
    stopListening();
  } else if (currentState === 'error') {
    addDebugLog('üîÑ Retrying voice recognition...');
    // Try to reinitialize
    await initializeVoiceRecognition();
  }
}

// Start listening for voice input
async function startListening() {
  if (!isVoiceSupported) {
    addDebugLog('üçÇ Voice not supported');
    updateState('error');
    return;
  }
  
  // Test microphone access first
  if (!microphonePermissionGranted) {
    addDebugLog('üé§ Testing microphone access...');
    const hasAccess = await testMicrophoneAccess();
    
    if (hasAccess) {
      addDebugLog('üé§ Microphone access confirmed - mic working!');
      microphonePermissionGranted = true;
      addDebugLog('üé§ Mic working - ready for voice input');
    } else {
      addDebugLog('üé§ Microphone access denied, opening permission page...');
      try {
        await requestMicrophonePermission();
      } catch (error) {
        addDebugLog(`üçÇ Microphone permission denied: ${error.message}`);
        updateState('error');
        return;
      }
    }
  } else {
    addDebugLog('üé§ Microphone permission already granted - mic working!');
  }
  
  try {
    addDebugLog('üé§ Starting voice recognition...');
    isListening = true;
    updateState('listening');
    
    // Start timeout for silence detection
    startVoiceTimeout();
    
    recognition.start();
  } catch (error) {
    addDebugLog(`üçÇ Voice recognition start error: ${error.message}`);
    updateState('error');
  }
}

// Stop listening
function stopListening() {
  if (recognition && isListening) {
    console.log('üé§ Stopping voice recognition...');
    recognition.stop();
  }
  
  // Clear timeout and reset state
  if (voiceTimeout) {
    clearTimeout(voiceTimeout);
    voiceTimeout = null;
  }
  isListening = false;
  updateState('ready');
}

// Request microphone permission using separate tab
async function requestMicrophonePermission() {
  addDebugLog('üé§ Requesting microphone permission via separate tab...');
  
  return new Promise((resolve, reject) => {
    // Open permission page in a new tab
    chrome.tabs.create({
      url: chrome.runtime.getURL('permission.html'),
      active: true
    }, (tab) => {
      if (chrome.runtime.lastError) {
        addDebugLog(`üçÇ Failed to open permission tab: ${chrome.runtime.lastError.message}`);
        reject(new Error(chrome.runtime.lastError.message));
        return;
      }
      
      addDebugLog(`üé§ Permission tab opened with ID: ${tab.id}`);
      
      // Listen for messages from the permission tab
      const handleMessage = (message, sender, sendResponse) => {
        if (sender.tab && sender.tab.id === tab.id) {
          if (message.type === 'MICROPHONE_PERMISSION_GRANTED') {
            addDebugLog('üé§ Microphone permission granted via tab');
            microphonePermissionGranted = true;
            chrome.tabs.remove(tab.id);
            resolve();
          } else if (message.type === 'MICROPHONE_PERMISSION_DENIED') {
            addDebugLog(`üçÇ Microphone permission denied via tab: ${message.error}`);
            microphonePermissionGranted = false;
            chrome.tabs.remove(tab.id);
            reject(new Error(message.error || 'Permission denied'));
          } else if (message.type === 'CLOSE_IFRAME') {
            addDebugLog('üé§ Permission tab closed by user');
            chrome.tabs.remove(tab.id);
            reject(new Error('Permission request cancelled'));
          }
        }
      };
      
      // Listen for tab removal (user closed tab)
      const handleTabRemoved = (tabId) => {
        if (tabId === tab.id) {
          addDebugLog('üé§ Permission tab was closed by user');
          reject(new Error('Permission request cancelled'));
        }
      };
      
      chrome.runtime.onMessage.addListener(handleMessage);
      chrome.tabs.onRemoved.addListener(handleTabRemoved);
      
      // Cleanup function
      const cleanup = () => {
        chrome.runtime.onMessage.removeListener(handleMessage);
        chrome.tabs.onRemoved.removeListener(handleTabRemoved);
      };
      
      // Timeout after 60 seconds
      setTimeout(() => {
        addDebugLog('üçÇ Permission request timed out');
        cleanup();
        chrome.tabs.remove(tab.id);
        reject(new Error('Permission request timed out'));
      }, 60000);
    });
  });
}

// Test microphone access directly
async function testMicrophoneAccess() {
  addDebugLog('üé§ Testing microphone access...');
  
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    
    // Test the stream
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    const source = audioContext.createMediaStreamSource(stream);
    const analyser = audioContext.createAnalyser();
    source.connect(analyser);
    
    // Check if we can read audio data
    const bufferLength = analyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    analyser.getByteFrequencyData(dataArray);
    
    // Stop the tracks
    stream.getTracks().forEach(track => track.stop());
    audioContext.close();
    
    addDebugLog('üé§ Microphone access confirmed - mic working!');
    return true;
  } catch (error) {
    addDebugLog(`üçÇ Microphone access test failed: ${error.name}`);
    return false;
  }
}

// Start voice timeout
function startVoiceTimeout() {
  if (voiceTimeout) {
    clearTimeout(voiceTimeout);
  }
  
  voiceTimeout = setTimeout(() => {
    console.log('üé§ Voice timeout - stopping due to silence');
    stopListening();
  }, VOICE_TIMEOUT_MS);
}

// Voice recognition event handlers
function handleVoiceStart() {
  addDebugLog('üé§ Voice recognition started');
  updateState('listening');
}

function handleVoiceResult(event) {
  const transcript = event.results[0][0].transcript.toLowerCase().trim();
  addDebugLog(`üé§ Voice input received: "${transcript}"`);
  
  // Check for wake words
  const containsWakeWord = WAKE_WORDS.some(wakeWord =>
    transcript.includes(wakeWord.toLowerCase())
  );
  
  if (containsWakeWord && !wakeWordDetected) {
    wakeWordDetected = true;
    addDebugLog(`üé§ Wake word detected: "${transcript}"`);
    return; // Continue listening for the actual command
  }
  
  // Update last transcript time
  if (voiceTimeout) {
    clearTimeout(voiceTimeout);
    startVoiceTimeout();
  }
  
  // Process the voice command
  processVoiceCommand(transcript);
}

function handleVoiceError(event) {
  addDebugLog(`üçÇ Voice recognition error: ${event.error}`);
  
  let errorMessage = 'Voice input failed';
  
  switch (event.error) {
    case 'no-speech':
      errorMessage = 'No speech detected';
      break;
    case 'audio-capture':
      errorMessage = 'Microphone not available';
      break;
    case 'not-allowed':
      errorMessage = 'Microphone permission denied';
      break;
    case 'network':
      errorMessage = 'Network error';
      break;
    default:
      errorMessage = `Voice error: ${event.error}`;
  }
  
  updateState('error');
  setTimeout(() => {
    updateState('ready');
  }, 3000);
}

function handleVoiceEnd() {
  addDebugLog('üé§ Voice recognition ended');
  isListening = false;
  wakeWordDetected = false; // Reset wake word detection
  updateState('ready');
  
  // Clear timeout
  if (voiceTimeout) {
    clearTimeout(voiceTimeout);
    voiceTimeout = null;
  }
}

// Process voice commands
async function processVoiceCommand(transcript) {
  addDebugLog(`üß† Processing voice command: "${transcript}"`);
  updateState('processing');
  
  const command = transcript.toLowerCase().trim();
  
  try {
    // Check for wake word
    if (command.includes('hey sherpa') || command.includes('hey sherpa 2')) {
      addDebugLog('üéØ Wake word detected');
      speakResponse("I'm listening. What can I help you with?");
      updateState('ready');
      return;
    }
    
    // Navigation commands
    if (command.includes('take me to') || command.includes('go to') || command.includes('navigate to')) {
      addDebugLog('üß≠ Processing navigation command');
      await handleNavigationCommand(command);
    }
    // On-page assistance
    else if (command.includes('where is') || command.includes('find') || command.includes('show me')) {
      addDebugLog('üîç Processing on-page command');
      await handleOnPageCommand(command);
    }
    // General help
    else if (command.includes('help') || command.includes('what can you do')) {
      addDebugLog('‚ùì Processing help command');
      handleHelpCommand();
    }
    // Fallback - web search
    else {
      addDebugLog('üîç Processing web search command');
      await handleWebSearchCommand(command);
      }
      
  } catch (error) {
    addDebugLog(`üçÇ Error processing voice command: ${error.message}`);
    speakResponse("Sorry, I couldn't process that command. Please try again.");
    updateState('ready');
  }
}

// Handle navigation commands
async function handleNavigationCommand(command) {
  addDebugLog(`üß≠ Handling navigation command: "${command}"`);
  
  // Extract destination from command
  let destination = command
    .replace(/take me to|go to|navigate to/gi, '')
    .trim();
  
  // Clean up common words
  destination = destination
    .replace(/^(the|a|an)\s+/i, '')
    .trim();
  
  addDebugLog(`üéØ Extracted destination: "${destination}"`);
  
  if (!destination) {
    addDebugLog('‚ùì No destination provided');
    speakResponse("Where would you like me to take you?");
    updateState('ready');
    return;
  }
  
  // Try to construct URL
  let url = destination;
  
  // Add protocol if missing
  if (!url.startsWith('http://') && !url.startsWith('https://')) {
    // Check if it looks like a domain
    if (url.includes('.') && !url.includes(' ')) {
      url = 'https://' + url;
      addDebugLog(`üåê Added https:// protocol: ${url}`);
  } else {
      // Treat as search query
      url = `https://www.google.com/search?q=${encodeURIComponent(destination)}`;
      addDebugLog(`üîç Treating as search query: ${url}`);
    }
  }
  
  addDebugLog(`üåê Navigating to: ${url}`);
  speakResponse(`Opening ${destination}`);
  
  // Navigate to the URL
  try {
    const [tab] = await chrome.tabs.query({ active: true, currentWindow: true });
    await chrome.tabs.update(tab.id, { url: url });
    addDebugLog('‚úÖ Navigation successful');
    updateState('ready');
    } catch (error) {
    addDebugLog(`üçÇ Navigation error: ${error.message}`);
    speakResponse("Sorry, I couldn't navigate to that destination.");
    updateState('ready');
  }
}

// Handle on-page assistance commands
async function handleOnPageCommand(command) {
  addDebugLog(`üîç Handling on-page command: "${command}"`);
  
  // Extract search term from command
  let searchTerm = command
    .replace(/where is|find|show me/gi, '')
    .trim();
  
  addDebugLog(`üéØ Extracted search term: "${searchTerm}"`);
  
  if (!searchTerm) {
    addDebugLog('‚ùì No search term provided');
    speakResponse("What would you like me to find on this page?");
    updateState('ready');
    return;
  }
  
  addDebugLog(`üîç Searching for: "${searchTerm}"`);
  speakResponse(`Looking for ${searchTerm} on this page`);
  
  // Send message to content script to search the page
  try {
    const [tab] = await chrome.tabs.query({ active: true, currentWindow: true });
    addDebugLog(`üì® Sending search message to tab: ${tab.id}`);
    
    const response = await chrome.tabs.sendMessage(tab.id, {
      action: 'searchOnPage',
      searchTerm: searchTerm
    });
    
    addDebugLog(`üì® Received response: ${JSON.stringify(response)}`);
    
    if (response && response.found) {
      addDebugLog(`‚úÖ Found ${response.results.length} matches`);
      speakResponse(`Found ${searchTerm}. ${response.message}`);
    } else {
      addDebugLog('‚ùå No matches found');
      speakResponse(`I couldn't find ${searchTerm} on this page.`);
    }
  } catch (error) {
    addDebugLog(`üçÇ On-page search error: ${error.message}`);
    speakResponse("Sorry, I couldn't search this page.");
  }
  
  updateState('ready');
}

// Handle help command
function handleHelpCommand() {
  addDebugLog('‚ùì Handling help command');
  
  const helpText = "I can help you navigate to websites, find elements on pages, or search the web. Try saying 'take me to google.com' or 'find the search button'.";
  speakResponse(helpText);
  updateState('ready');
}

// Handle web search commands
async function handleWebSearchCommand(command) {
  addDebugLog(`üîç Handling web search command: "${command}"`);
  
  speakResponse(`Searching for ${command}`);
  
  // Use Google search
  const searchUrl = `https://www.google.com/search?q=${encodeURIComponent(command)}`;
  addDebugLog(`üîç Search URL: ${searchUrl}`);
  
  try {
    const [tab] = await chrome.tabs.query({ active: true, currentWindow: true });
    await chrome.tabs.update(tab.id, { url: searchUrl });
    addDebugLog('‚úÖ Web search navigation successful');
    updateState('ready');
  } catch (error) {
    addDebugLog(`üçÇ Web search error: ${error.message}`);
    speakResponse("Sorry, I couldn't perform that search.");
    updateState('ready');
  }
}

// Text-to-speech function
function speakResponse(text) {
  addDebugLog(`üîä Speaking: "${text}"`);
  
  if ('speechSynthesis' in window) {
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.rate = 0.9;
    utterance.pitch = 1.0;
    utterance.volume = 0.8;
    speechSynthesis.speak(utterance);
    } else {
    addDebugLog('üçÇ Speech synthesis not supported');
  }
}

// Update UI state
function updateState(state) {
  addDebugLog(`üîÑ State change: ${currentState} ‚Üí ${state}`);
  currentState = state;
  
  // Remove all state classes
  sherpaCircle.classList.remove('listening', 'processing', 'ready', 'error');
  statusText.classList.remove('listening', 'processing', 'ready', 'error');
  
  // Add new state class
  if (state !== 'idle') {
    sherpaCircle.classList.add(state);
    statusText.classList.add(state);
  }
  
  // Update icon and text
    switch (state) {
    case 'idle':
      sherpaIcon.textContent = '‚óã';
      statusText.textContent = 'Ready';
      break;
      case 'listening':
      sherpaIcon.textContent = '‚óè';
      statusText.textContent = 'Listening...';
        break;
      case 'processing':
      sherpaIcon.textContent = '‚óê';
      statusText.textContent = 'Processing...';
        break;
      case 'ready':
      sherpaIcon.textContent = '‚óã';
      if (microphonePermissionGranted) {
        statusText.textContent = 'Mic working - Ready to help';
      } else {
        statusText.textContent = 'Ready to help';
      }
        break;
    case 'error':
      sherpaIcon.textContent = '‚ñ≤';
      statusText.textContent = 'Error - Click to retry';
      break;
  }
}

// Debug logging functions
function setupDebugLogHandlers() {
  // Copy log button
  copyLogBtnEl.addEventListener('click', copyDebugLog);
  
  // Clear log button
  clearLogBtnEl.addEventListener('click', clearDebugLog);
  
  // Toggle log button
  logToggleBtnEl.addEventListener('click', toggleDebugLog);
}

function addDebugLog(message) {
  const timestamp = new Date().toLocaleTimeString();
  const logEntry = `[${timestamp}] ${message}`;
  
  // Add to buffer
  logBuffer.push(logEntry);
  
  // Keep only recent entries
  if (logBuffer.length > MAX_LOG_ENTRIES) {
    logBuffer = logBuffer.slice(-MAX_LOG_ENTRIES);
  }
  
  // Console log immediately
  console.log(logEntry);
  
  // Update display with throttling
  if (!logUpdateInterval) {
    logUpdateInterval = setTimeout(updateLogDisplay, 100);
  }
}

function updateLogDisplay() {
  if (logBuffer.length === 0) return;
  
  // Show more lines since we have more space
  const displayLines = logBuffer.slice(-80);
  debugContentEl.textContent = displayLines.join('\n');
  debugContentEl.scrollTop = debugContentEl.scrollHeight;
  
  // Clear the interval
  logUpdateInterval = null;
}

function clearDebugLog() {
  debugContentEl.textContent = '';
  logBuffer = [];
  
  if (logUpdateInterval) {
    clearTimeout(logUpdateInterval);
    logUpdateInterval = null;
  }
  
  addDebugLog('üßπ Debug log cleared');
}

async function copyDebugLog() {
  try {
    const logText = logBuffer.join('\n');
    if (!logText.trim()) {
      addDebugLog('üçÇ No log content to copy');
      return;
    }
    
    await navigator.clipboard.writeText(logText);
    addDebugLog('üìã Log copied to clipboard!');
    
    // Visual feedback
    const originalText = copyLogBtnEl.textContent;
    copyLogBtnEl.textContent = '‚úÖ Copied!';
    copyLogBtnEl.style.background = '#16a34a';
    
    setTimeout(() => {
      copyLogBtnEl.textContent = originalText;
      copyLogBtnEl.style.background = '#404040';
    }, 1500);
    
  } catch (error) {
    addDebugLog(`üçÇ Failed to copy log: ${error.message}`);
  }
}

function toggleDebugLog() {
  debugEl.classList.toggle('collapsed');
  document.body.classList.toggle('log-expanded');
  
  // Update toggle button icon
  if (debugEl.classList.contains('collapsed')) {
    logToggleIconEl.textContent = '+';
    addDebugLog('üå≤ Debug log collapsed');
  } else {
    logToggleIconEl.textContent = '‚àí';
    addDebugLog('üå≤ Debug log expanded');
  }
}
